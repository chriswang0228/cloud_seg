# -*- coding: utf-8 -*-
"""tileseg_unet_code(peel) (5).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ip0UbtuhWs1Rrgww7nyiGZNtizJypDPF

# What is Semantic Segmentation?
Semantic segmentation refers to the process of linking each pixel in an image to a class label. These labels could include a person, car, flower, piece of furniture, etc., just to mention a few.
We can think of semantic segmentation as image classification at a pixel level. For example, in an image that has many cars, segmentation will label all the objects as car objects. However, a separate class of models known as instance segmentation is able to label the separate instances where an object appears in an image. This kind of segmentation can be very useful in applications that are used to count the number of objects, such as counting the amount of foot traffic in a mall.

# Please upvote the kernel if you found it insightful!

# Import Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
import torchvision
import torch.nn.functional as F
from torch.autograd import Variable

from PIL import Image
import cv2
import albumentations as A

import time
import os
from tqdm.notebook import tqdm
import random


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(0)
random.seed(0)
np.random.seed(0)


"""# Preprocessing"""

IMAGE_PATH = '/Data/cloud/compression_img_2000/'
height=1024
width=1024
n_classes=3

class DroneTestDataset(Dataset):
    
    def __init__(self, img_path, X, transform=None):
        self.img_path = img_path
        self.X = X
        self.transform = transform
      
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        img = cv2.imread(self.img_path + self.X[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        if self.transform is not None:
            aug = self.transform(image=img)
            img = Image.fromarray(aug['image'])
        
        if self.transform is None:
            img = Image.fromarray(img)
                
        return img, self.X[idx]
    
t_test = A.Resize(height, width, interpolation=cv2.INTER_NEAREST)

def predict_image(model, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    model.eval()
    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])
    image = t(image)
    model.to(device); image=image.to(device)
    with torch.no_grad():
        image = image.unsqueeze(0)
        output = model(image)
        result=torch.argmax(output, dim=1).squeeze(0)
    return result

arch_list=['Unet','UPP']
test_set = DroneTestDataset(IMAGE_PATH, os.listdir(IMAGE_PATH), transform=t_test)
for arch in arch_list:
    model=torch.load('../model_weight/EFFB6/cloud_'+arch+'.pt')
    model.eval()
    for i,test in enumerate(test_set):
        result=predict_image(model, test[0]).cpu().numpy()
        result=result.reshape(test[0].size[:2])
        
        #result[:,:222]=3
        #result[:,802:]=3
        
        result[:,:33]=3
        result[:,990:]=3
        cv2.imwrite(f'../prediction/2000/{arch}/{test[1]}', result)